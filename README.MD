Sempre exibir os detalhes

from pathlib import Path

readme_content = """
# ğŸ’¥ MemeBot Backend

Este projeto Ã© um backend construÃ­do com **FastAPI** para buscar **tokens do tipo meme** da DexScreener, usando scraping inteligente com **Playwright**. Os dados sÃ£o expostos via API REST no endpoint `/signals`.

---

## ğŸš€ Como iniciar o projeto

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/memebot-backend.git
cd memebot-backend
2. Crie e ative um ambiente virtual
Sempre exibir os detalhes

python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\\Scripts\\activate     # Windows
3. Instale as dependÃªncias
Sempre exibir os detalhes

pip install -r requirements.txt
Se ainda nÃ£o existir o arquivo requirements.txt, use:

Sempre exibir os detalhes

pip install fastapi uvicorn playwright
E depois:

Sempre exibir os detalhes

playwright install
Isso instala os navegadores necessÃ¡rios para rodar o scraping com Chromium.
ğŸ› ï¸ Rodando o servidor localmente
Sempre exibir os detalhes

uvicorn app.main:app --reload
Acesse a API em:

http://127.0.0.1:8000/docs â†’ documentaÃ§Ã£o interativa Swagger UI
http://127.0.0.1:8000/signals â†’ lista de tokens meme extraÃ­dos da DexScreener
ğŸ“ Estrutura de pastas
Sempre exibir os detalhes

memebot-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Inicializa o app FastAPI
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ signal_model.py    # Define o modelo Signal
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ signals.py         # Endpoint /signals
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ scraper.py         # Faz scraping da DexScreener
â”œâ”€â”€ venv/                      # Ambiente virtual (nÃ£o subir para o Git)
â””â”€â”€ README.md                  # Este arquivo
ğŸ§ª Testando
Acesse a rota /signals no navegador ou com cURL:

Sempre exibir os detalhes

curl http://127.0.0.1:8000/signals
ğŸ§¼ Dicas
Se der erro Cannot GET /... ou Expecting value: line 1 column 1, Ã© porque a DexScreener bloqueia acesso direto da API. Por isso, usamos o Playwright com navegador real no scraper.py.
ğŸ“Œ Requisitos
Python 3.9 ou superior
Navegador instalado via Playwright (playwright install)
ğŸ“ Status atual
âœ… Scraping funcionando
âœ… API rodando com FastAPI
ğŸš§ Falta coletar dados completos da tabela (volume, preÃ§o, liquidez)
ğŸš§ Futuro: integrar com frontend, banco de dados e alertas

Feito com ğŸ’» por [Seu Nome]
"""

readme_path = Path("README.md")
readme_path.write_text(readme_content.strip(), encoding="utf-8")

readme_path.name

Sempre exibir os detalhes

Resultado
'README.md'